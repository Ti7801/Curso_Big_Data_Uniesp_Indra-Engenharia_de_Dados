# DESAFIO 2 SEMANA BIG DATA HIVE

É muito importante entender o fluxo de desenvolvimento de um pipeline de dados, neste desafio você executar a 1 ingestão que já esta configurada.

etapa 1 - executar rollout.sh
etapa 2 - executar o malha/jobs.sh (primeira ingestão), contudo que se pede
etapa 3 - desenhar um mapa mental da solução em qualquer ferramenta eu uso muito o (Draw.io), detalhando as etapas passando por cada script, detalhando o máximo o entendimento de vocês.
etapa 4 - configurar e executar a ingestão da pasta dados/second_ingestion
etapa 5 - executa o rollback.sh


### IMPORTANTE

este desafio não é obrigatório, tem apenas como finalidade passar um cenário de um projeto possível, para que vocês tenham uma noção como é o dia a dia de um Engenheiro de Dados.
**desta vez a maneira já esta criada, procure entender o máximo que for possível**.

* Pesquise
* Neste projeto foi usando muitas variável globais em Linux, nome de pasta passando por parâmetro...
* Converse com seus Amigos
* Compartilhe seus resultados em suas redes
* Se divirta
* Aprenda bastante
* Usem o github
       
## Etapas e Explicações

SERVIDOR: hive-server

1 - Efetuar o Download do pacote usando o CURL ou usar o Github para clonar o projeto

curl -O https://github.com/caiuafranca/desafio_bigdata_hive/archive/refs/heads/master.zip

ou git clone https://github.com/caiuafranca/desafio_bigdata_hive.git

### OBS

usem e abusem do echo para evidenciar o seu processo em tela

echo "Aproveitem a Jornada para adquirir conhecimento"